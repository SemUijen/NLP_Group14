{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c35f761-6e70-40b5-9ec0-27a9ee20e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize \n",
    "import matplotlib.pyplot as plt\n",
    "#Find the ten most/least common words\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03488397-c66f-4d96-a11e-eb76426367af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wait direction market stock market difficult t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mid year update u s canadian stock market sect...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trade apple earning apple earning preview quar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>market bait switch sound go hear soon btfd cro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aapl fall tree apple s aapl sale quarter miss ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  wait direction market stock market difficult t...       1\n",
       "1  mid year update u s canadian stock market sect...       1\n",
       "2  trade apple earning apple earning preview quar...       1\n",
       "3  market bait switch sound go hear soon btfd cro...       0\n",
       "4  aapl fall tree apple s aapl sale quarter miss ...       1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_apple = pd.read_csv(\"../data/aapl_us_equities_news_prep_text_consol_text_html_inval_upper_char_lemmas_stopwords.csv\")\n",
    "df_apple.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e460ba0-3ba5-4425-9c12-c54118e28d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apple_increase = df_apple[df_apple['target']==1]\n",
    "tokens_pos = df_apple_increase['text'].apply(word_tokenize)\n",
    "\n",
    "ALL_tokens_positive = []\n",
    "for token_list in tokens_pos:\n",
    "    ALL_tokens_positive.extend(token_list)\n",
    "\n",
    "    \n",
    "df_apple_decrease = df_apple[df_apple['target']==0]\n",
    "tokens_neg = df_apple_decrease['text'].apply(word_tokenize)    \n",
    "\n",
    "ALL_tokens_neg = []\n",
    "for token_list in tokens_neg:\n",
    "    ALL_tokens_neg.extend(token_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "605cb4b5-e765-4d8c-ad85-a9dd616e978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the ten most/least common words\n",
    "from collections import Counter\n",
    "counted_pos = Counter(ALL_tokens_positive)\n",
    "counted_neg = Counter(ALL_tokens_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e108e7a6-ba66-43e9-b85a-757e1dd9b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Intersect = counted_pos - counted_neg\n",
    "\n",
    "for item, count in Intersect.items():\n",
    "\n",
    "    Intersect[item] /= counted_pos[item] + counted_neg[item]\n",
    "\n",
    "intersect_above_80 = Counter({x: count for x, count in Intersect.items() if count >= 0.2})\n",
    "\n",
    "Pos_candidates = []\n",
    "for item, count in intersect_above_80.items():\n",
    "    if counted_pos[item] > 10:\n",
    "        Pos_candidates.append((item,counted_pos[item]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aadb25-17ff-457d-b37e-6668052515ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize word cloud\n",
    "moby_dick_str = \" \".join(ALL_tokens_positive)\n",
    "wordcloud = WordCloud(width = 1600, height = 800,\n",
    "background_color ='white',\n",
    "min_font_size =\n",
    "10).generate(moby_dick_str)\n",
    "\n",
    "#Create the Word cloud\n",
    "plt.figure(figsize = (16, 8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe3c03a-2d9c-4954-9fec-0d4dd400248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize word cloud\n",
    "moby_dick_str = \" \".join(ALL_tokens_neg)\n",
    "wordcloud = WordCloud(width = 1600, height = 800,\n",
    "background_color ='white',\n",
    "min_font_size =\n",
    "10).generate(moby_dick_str)\n",
    "\n",
    "#Create the Word cloud\n",
    "plt.figure(figsize = (16, 8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf5b5a2c-f009-4da2-a73d-24d7f44a0e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d65b9ccb-8570-4bd9-964e-b676481ae83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ngrams(data, num):\n",
    "    n_grams = ngrams(data, num)\n",
    "    return [ ' '.join(grams) for grams in n_grams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aaac52ef-c162-43d7-8993-ef3ab366aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = extract_ngrams(ALL_tokens_positive,2)\n",
    "Ngrams_pos_counted = Counter(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "361810c0-43f6-46ad-bebd-b92960ab3c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = extract_ngrams(ALL_tokens_neg,2)\n",
    "Ngrams_neg_counted = Counter(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ecf2710a-c8ae-4fba-9342-b6c1915d459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Intersect = Ngrams_pos_counted - Ngrams_neg_counted\n",
    "\n",
    "for item, count in Intersect.items():\n",
    "\n",
    "    Intersect[item] /= Ngrams_pos_counted[item] + Ngrams_neg_counted[item]\n",
    "\n",
    "intersect_above_80 = Counter({x: count for x, count in Intersect.items() if count >= 0.8})\n",
    "\n",
    "Pos_candidates = []\n",
    "for item, count in intersect_above_80.items():\n",
    "    if Ngrams_pos_counted[item] > 10:\n",
    "        Pos_candidates.append((item, Ngrams_pos_counted[item]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96934be7-a1a7-4544-b46f-8949e4b94836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wait direction', 1.0),\n",
       " ('difficult trader', 1.0),\n",
       " ('alike directionless', 1.0),\n",
       " ('directionless choppiness', 1.0),\n",
       " ('choppiness combine', 1.0),\n",
       " ('climate maximum', 1.0),\n",
       " ('maximum frustration', 1.0),\n",
       " ('frustration professional', 1.0),\n",
       " ('professional talk', 1.0),\n",
       " ('talk unfortunately', 1.0)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersect_above_80.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd146c5c-7635-479a-9983-22e1a6170cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "def n_containing(word, bloblist):\n",
    "    return counted_pos[word]+counted_neg[word]\n",
    "def idf(word, bloblist):\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebaa016a-152b-4c7f-b5a3-5ca54fa7bf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apple_increase = df_apple[df_apple['target']==1]\n",
    "df_apple_decrease = df_apple[df_apple['target']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c75e5571-ce4e-4690-a492-d58dd5687a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = []\n",
    "for text in df_apple_increase['text']:\n",
    "    all_text.append(text)\n",
    "\n",
    "Pos_docu = ' '.join(all_text)\n",
    "    \n",
    "all_text = []\n",
    "for text in df_apple_decrease['text']:\n",
    "    all_text.append(text)\n",
    "\n",
    "Neg_docu = ' '.join(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9de8afa2-f967-49bb-afda-6d27188b5691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02896425-9346-4c93-9dc1-e64637ee1747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                        | 471/3271843 [02:00<221:55:09,  4.09it/s]"
     ]
    }
   ],
   "source": [
    "bloblist = [tb(Pos_docu),tb(Neg_docu)]\n",
    "results = []\n",
    "for i, blob in enumerate(bloblist):\n",
    "    print(\"Top words in document {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in tqdm(blob.words)}\n",
    "    results.append(scores)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f6576e-3af1-4fda-839f-dff3ae5e6490",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "results.append(sorted_words)\n",
    "for word, score in sorted_words[:50]:\n",
    "    print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
