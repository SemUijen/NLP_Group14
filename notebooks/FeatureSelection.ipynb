{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c35f761-6e70-40b5-9ec0-27a9ee20e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize \n",
    "import matplotlib.pyplot as plt\n",
    "#Find the ten most/least common words\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03488397-c66f-4d96-a11e-eb76426367af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apple = pd.read_csv(\"../data/aapl_us_equities_news_prep_text_consol_text_html_inval_upper_char_lemmas_stopwords.csv\")\n",
    "df_apple.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e460ba0-3ba5-4425-9c12-c54118e28d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apple_increase = df_apple[df_apple['target']==1]\n",
    "tokens_pos = df_apple_increase['text'].apply(word_tokenize)\n",
    "\n",
    "ALL_tokens_positive = []\n",
    "for token_list in tokens_pos:\n",
    "    ALL_tokens_positive.extend(token_list)\n",
    "\n",
    "    \n",
    "df_apple_decrease = df_apple[df_apple['target']==0]\n",
    "tokens_neg = df_apple_decrease['text'].apply(word_tokenize)    \n",
    "\n",
    "ALL_tokens_neg = []\n",
    "for token_list in tokens_neg:\n",
    "    ALL_tokens_neg.extend(token_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "605cb4b5-e765-4d8c-ad85-a9dd616e978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the ten most/least common words\n",
    "from collections import Counter\n",
    "counted_pos = Counter(ALL_tokens_positive)\n",
    "counted_neg = Counter(ALL_tokens_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e108e7a6-ba66-43e9-b85a-757e1dd9b0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38395\n",
      "38395\n",
      "52932\n"
     ]
    }
   ],
   "source": [
    "Intersect = counted_pos - counted_neg\n",
    "\n",
    "for item, count in Intersect.items():\n",
    "\n",
    "    Intersect[item] /= counted_pos[item] + counted_neg[item]\n",
    "\n",
    "intersect_above_80 = Counter({x: count for x, count in Intersect.items() if count >= 0.2})\n",
    "\n",
    "Pos_candidates = []\n",
    "for item, count in intersect_above_80.items():\n",
    "    if counted_pos[item] > 10:\n",
    "        Pos_candidates.append((item,counted_pos[item]))\n",
    "print(Pos_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aadb25-17ff-457d-b37e-6668052515ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize word cloud\n",
    "moby_dick_str = \" \".join(ALL_tokens_positive)\n",
    "wordcloud = WordCloud(width = 1600, height = 800,\n",
    "background_color ='white',\n",
    "min_font_size =\n",
    "10).generate(moby_dick_str)\n",
    "\n",
    "#Create the Word cloud\n",
    "plt.figure(figsize = (16, 8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe3c03a-2d9c-4954-9fec-0d4dd400248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize word cloud\n",
    "moby_dick_str = \" \".join(ALL_tokens_neg)\n",
    "wordcloud = WordCloud(width = 1600, height = 800,\n",
    "background_color ='white',\n",
    "min_font_size =\n",
    "10).generate(moby_dick_str)\n",
    "\n",
    "#Create the Word cloud\n",
    "plt.figure(figsize = (16, 8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf5b5a2c-f009-4da2-a73d-24d7f44a0e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d65b9ccb-8570-4bd9-964e-b676481ae83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ngrams(data, num):\n",
    "    n_grams = ngrams(data, num)\n",
    "    return [ ' '.join(grams) for grams in n_grams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aaac52ef-c162-43d7-8993-ef3ab366aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = extract_ngrams(ALL_tokens_positive,2)\n",
    "Ngrams_pos_counted = Counter(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "361810c0-43f6-46ad-bebd-b92960ab3c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = extract_ngrams(ALL_tokens_neg,2)\n",
    "Ngrams_neg_counted = Counter(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ecf2710a-c8ae-4fba-9342-b6c1915d459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Intersect = Ngrams_pos_counted - Ngrams_neg_counted\n",
    "\n",
    "for item, count in Intersect.items():\n",
    "\n",
    "    Intersect[item] /= Ngrams_pos_counted[item] + Ngrams_neg_counted[item]\n",
    "\n",
    "intersect_above_80 = Counter({x: count for x, count in Intersect.items() if count >= 0.8})\n",
    "\n",
    "Pos_candidates = []\n",
    "for item, count in intersect_above_80.items():\n",
    "    if Ngrams_pos_counted[item] > 10:\n",
    "        Pos_candidates.append((item, Ngrams_pos_counted[item]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96934be7-a1a7-4544-b46f-8949e4b94836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wait direction', 1.0),\n",
       " ('difficult trader', 1.0),\n",
       " ('alike directionless', 1.0),\n",
       " ('directionless choppiness', 1.0),\n",
       " ('choppiness combine', 1.0),\n",
       " ('climate maximum', 1.0),\n",
       " ('maximum frustration', 1.0),\n",
       " ('frustration professional', 1.0),\n",
       " ('professional talk', 1.0),\n",
       " ('talk unfortunately', 1.0)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersect_above_80.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd146c5c-7635-479a-9983-22e1a6170cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob.words)\n",
    "def idf(word, bloblist):\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebaa016a-152b-4c7f-b5a3-5ca54fa7bf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apple_increase = df_apple[df_apple['target']==1]\n",
    "df_apple_decrease = df_apple[df_apple['target']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c75e5571-ce4e-4690-a492-d58dd5687a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = []\n",
    "for text in df_apple_increase['text']:\n",
    "    all_text.append(text)\n",
    "\n",
    "Pos_docu = ' '.join(all_text)\n",
    "    \n",
    "all_text = []\n",
    "for text in df_apple_decrease['text']:\n",
    "    all_text.append(text)\n",
    "\n",
    "Neg_docu = ' '.join(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02896425-9346-4c93-9dc1-e64637ee1747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, blob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(bloblist):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop words in document \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m     scores \u001b[38;5;241m=\u001b[39m {word: tfidf(word, blob, bloblist) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m blob\u001b[38;5;241m.\u001b[39mwords}\n\u001b[0;32m      6\u001b[0m     sorted_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(scores\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(sorted_words)\n",
      "Cell \u001b[1;32mIn [21], line 5\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, blob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(bloblist):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop words in document \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m     scores \u001b[38;5;241m=\u001b[39m {word: \u001b[43mtfidf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbloblist\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m blob\u001b[38;5;241m.\u001b[39mwords}\n\u001b[0;32m      6\u001b[0m     sorted_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(scores\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(sorted_words)\n",
      "Cell \u001b[1;32mIn [6], line 10\u001b[0m, in \u001b[0;36mtfidf\u001b[1;34m(word, blob, bloblist)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtfidf\u001b[39m(word, blob, bloblist):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblob\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m idf(word, bloblist)\n",
      "Cell \u001b[1;32mIn [6], line 4\u001b[0m, in \u001b[0;36mtf\u001b[1;34m(word, blob)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtf\u001b[39m(word, blob):\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mblob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(blob\u001b[38;5;241m.\u001b[39mwords)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bloblist = [tb(Pos_docu),tb(Neg_docu)]\n",
    "results = []\n",
    "for i, blob in enumerate(bloblist):\n",
    "    print(\"Top words in document {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    results.append(sorted_words)\n",
    "    for word, score in sorted_words[:50]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f6576e-3af1-4fda-839f-dff3ae5e6490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
