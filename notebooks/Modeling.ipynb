{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ef3d281-c272-452d-8b56-053dfa1e738d",
   "metadata": {},
   "source": [
    "# 1. Modeling\n",
    "\n",
    "Bron: https://iq.opengenus.org/naive-bayes-on-tf-idf-vectorized-matrix/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f72c64a8-41c4-49a5-8f0b-ab9bf1b31647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "276b5210-6fd5-4b60-8d25-4d5b192e2fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINTS_FOLDER = \"../checkpoints/\"\n",
    "\n",
    "SAVE_MODEL_CHECKPOINTS = True\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5630270c-09da-45e9-9989-221b92207ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80dc452-5897-4339-bd04-c8292d0dcee2",
   "metadata": {},
   "source": [
    "## 1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "446f5fea-06a9-4a48-94e0-a8adaecbb628",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.read_csv(\"../data/aapl_us_equities_news_proc_text.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36b5829-6331-42d9-a99d-c665b781b538",
   "metadata": {},
   "source": [
    "## 1.2 Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "478fdea2-5235-4cd9-8c11-1f33ff9a138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_text[\"text\"],\n",
    "    df_text[\"target\"],\n",
    "    stratify=df_text[\"target\"],\n",
    "    random_state=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115e194-9b39-4e68-90c2-50dce43847e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.3 Build pipeline\n",
    "\n",
    "Bron: https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n",
    "\n",
    "Bron: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "Bron: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "Bron: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "Bron: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30e91073-fdd6-44b7-8280-99751fe1d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTORIZERS = [\n",
    "    (\"count_vec\", CountVectorizer()),\n",
    "    (\"tfidf_vec\", TfidfVectorizer()),\n",
    "]\n",
    "\n",
    "CLASSIFIERS = [\n",
    "    (\"ada_clf\", AdaBoostClassifier(random_state=RANDOM_SEED)),\n",
    "    (\"knn_clf\", KNeighborsClassifier()),\n",
    "    (\"lr_clf\", LogisticRegression(random_state=RANDOM_SEED)),\n",
    "    (\"nb_clf\", MultinomialNB()),\n",
    "    (\"rf_clf\", RandomForestClassifier(random_state=RANDOM_SEED)),\n",
    "    (\"sgd_clf\", SGDClassifier(random_state=RANDOM_SEED)),\n",
    "    (\"svc_clf\", SVC(random_state=RANDOM_SEED)),\n",
    "]\n",
    "\n",
    "PARAMETERS = {\n",
    "    # Count\n",
    "    \"count_vec__min_df\": [1.0, 0.05, 0.10, 0.15, 0.20], # Default: 1\n",
    "    \"count_vec__max_df\": [1.0, 0.85, 0.65, 0.50],       # Default: 1.0\n",
    "\n",
    "    # TFIDF\n",
    "    \"tfidf_vec__min_df\": [1.0, 0.05, 0.10, 0.15, 0.20], # Default: 1\n",
    "    \"tfidf_vec__max_df\": [1.0, 0.85, 0.65, 0.50],       # Default: 1.0\n",
    "    \"tfidf_vec__norm\": [\"l2\", \"l1\", None],              # Default: l2\n",
    "    \"tfidf_vec__use_idf\": [True, False],                # Default: True\n",
    "    \"tfidf_vec__smooth_idf\": [True, False],             # Default: True\n",
    "    \"tfidf_vec__sublinear_tf\": [False, True],           # Default: False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4465baf7-fa61-4270-9a05-d4396fcb31c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(count_vec, ada_clf): np=24, ns=5, tf=120:   0%|                                                                                                      | 0/7 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "timestamp = datetime.now().strftime(\"%-Y%m%d%H%M%S\")\n",
    "results = {}\n",
    "models = {}\n",
    "\n",
    "for vec_id, vec in VECTORIZERS:\n",
    "    clf_pb = tqdm(CLASSIFIERS)\n",
    "\n",
    "    for clf_id, clf in clf_pb:\n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline([(vec_id, vec), (clf_id, clf)])\n",
    "\n",
    "        # Select parameters\n",
    "        parameters = {k: v for k, v in PARAMETERS.items() if vec_id in k or clf_id in k}\n",
    "        n_params = reduce(lambda x, y: x * len(y), parameters.values(), 1)\n",
    "        n_splits = 5\n",
    "\n",
    "        # Setup search\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            parameters,\n",
    "            scoring=\"f1\",\n",
    "            return_train_score=True,\n",
    "            cv=n_splits,\n",
    "            n_jobs=-1,\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        # Log info\n",
    "        clf_pb.set_description(\n",
    "            f\"({vec_id}, {clf_id}): np={n_params}, ns={n_splits}, tf={n_params * n_splits}\",\n",
    "        )\n",
    "        clf_pb.refresh()\n",
    "\n",
    "        # Train model\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate model\n",
    "        clf = grid_search.best_estimator_\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "\n",
    "        y_test_pred = clf.predict(X_test)\n",
    "\n",
    "        test_score = f1_score(y_test, y_test_pred)\n",
    "\n",
    "        # Create results\n",
    "        idx = np.argmax(grid_search.cv_results_[\"mean_test_score\"])\n",
    "\n",
    "        result = {\n",
    "            \"mean_train_score\": grid_search.cv_results_[\"mean_train_score\"][idx],\n",
    "            \"std_train_score\": grid_search.cv_results_[\"std_train_score\"][idx],\n",
    "            \"mean_val_score\": grid_search.cv_results_[\"mean_test_score\"][idx],\n",
    "            \"std_val_score\": grid_search.cv_results_[\"std_test_score\"][idx],\n",
    "            \"test_score\": test_score,\n",
    "            \"params\": grid_search.best_params_,\n",
    "        }\n",
    "\n",
    "        # Store result\n",
    "        results[vec_id, clf_id] = result\n",
    "        models[vec_id, clf_id] = clf\n",
    "\n",
    "        if SAVE_MODEL_CHECKPOINTS:\n",
    "            with open(MODEL_CHECKPOINTS_FOLDER + f\"{timestamp}_{vec_id}_{clf_id}.json\", \"w\") as handle:\n",
    "                json.dump({f\"{k1}_{k2}\": v for (k1, k2), v in results.items()}, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735fcc6a-3caa-4cbf-9bac-5df6b4c3c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = -1.00\n",
    "best_vec_id = None\n",
    "best_clf_id = None\n",
    "best_values = None\n",
    "best_model = None\n",
    "\n",
    "for (vec_id, clf_id), values in results.items():\n",
    "    score = values[\"test_score\"]\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_vec_id = vec_id\n",
    "        best_clf_id = clf_id\n",
    "        best_values = values\n",
    "        best_model = models[vec_id, clf_id]\n",
    "\n",
    "print(\"-\" * 100 + \"\\n\")\n",
    "print(f\"Best Vectorizer: {best_vec_id}\")\n",
    "print(f\"Best Classifier: {best_clf_id}\" + \"\\n\")\n",
    "print(f\"Best Params:\")\n",
    "pprint(best_values[\"params\"])\n",
    "print(\"\")\n",
    "print(f\"Mean Train Score: {round(best_values['mean_train_score'], 4)}\")\n",
    "print(f\"Std Train Score: {round(best_values['std_train_score'], 4)}\")\n",
    "print(f\"Mean Validation Score: {round(best_values['mean_val_score'], 4)}\")\n",
    "print(f\"Std Validation Score: {round(best_values['std_val_score'], 4)}\" + \"\\n\")\n",
    "print(f\"Test Score: {round(best_values['test_score'], 4)}\")\n",
    "print(\"\\n\" + \"-\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
